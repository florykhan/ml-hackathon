{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 02 ‚Äî Preprocessing & Feature Engineering\n",
    "\n",
    "> **Objective:** To implement the cleaning and feature-engineering steps used in the overqualification pipeline: handling NGS special codes, normalizing mixed-type columns, and preparing categorical features for CatBoost.\n",
    "\n",
    "This notebook covers:\n",
    "1. [**Preprocessing**](#preprocessing) ‚Äî `clean()`: missing codes and categorical normalization  \n",
    "2. [**Feature engineering**](#feature-engineering) ‚Äî `add_features()`: categorical encoding for CatBoost  \n",
    "3. [**Before/after comparison**](#before-and-after-comparison) ‚Äî data shape and sample values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context",
   "metadata": {},
   "source": [
    "### üß† Context\n",
    "\n",
    "The NGS dataset uses **6, 9, 99** as valid skip / refused / not stated. The pipeline treats these as missing and fills them consistently. Columns such as **GENDER2**, **DDIS_FL**, and **VISBMINP** sometimes contain text (e.g. \"Female\", \"With disability\") in addition to numeric codes; we normalize these to numeric codes before converting to categorical strings for CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "---\n",
    "### üß∞ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from src.data import load_train\n",
    "from src.preprocess import clean\n",
    "from src.features import add_features, get_categorical_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {},
   "source": [
    "### üì• Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7709, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CERTLEVP</th>\n",
       "      <th>PGMCIPAP</th>\n",
       "      <th>PGM_P034</th>\n",
       "      <th>PGM_P036</th>\n",
       "      <th>PGM_280A</th>\n",
       "      <th>PGM_280B</th>\n",
       "      <th>PGM_280C</th>\n",
       "      <th>PGM_280F</th>\n",
       "      <th>PGM_P401</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADAGEP</th>\n",
       "      <th>GENDER2</th>\n",
       "      <th>CTZSHIPP</th>\n",
       "      <th>VISBMINP</th>\n",
       "      <th>DDIS_FL</th>\n",
       "      <th>PAR1GRD</th>\n",
       "      <th>PAR2GRD</th>\n",
       "      <th>BEF_P140</th>\n",
       "      <th>BEF_160</th>\n",
       "      <th>overqualified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7011</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6770</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  CERTLEVP  PGMCIPAP  PGM_P034  PGM_P036  PGM_280A  PGM_280B  PGM_280C  \\\n",
       "0   187       1.0       4.0       1.0       6.0       2.0       1.0       9.0   \n",
       "1  5343       2.0       5.0       1.0       6.0       2.0       6.0       2.0   \n",
       "2  7011       2.0      99.0       1.0       6.0       2.0       2.0       2.0   \n",
       "3  1519       1.0       7.0       1.0       6.0       2.0       2.0       2.0   \n",
       "4  6770       2.0       5.0       9.0       1.0       2.0       9.0       2.0   \n",
       "\n",
       "   PGM_280F  PGM_P401  ...  GRADAGEP  GENDER2  CTZSHIPP  VISBMINP  DDIS_FL  \\\n",
       "0       2.0       NaN  ...       1.0      2.0       2.0       1.0      2.0   \n",
       "1       9.0       2.0  ...       1.0      2.0       1.0       2.0      1.0   \n",
       "2       1.0       1.0  ...       1.0      2.0       2.0       1.0      2.0   \n",
       "3       1.0       1.0  ...       4.0      9.0       2.0       2.0      NaN   \n",
       "4       1.0       2.0  ...       1.0      NaN       1.0       2.0      1.0   \n",
       "\n",
       "   PAR1GRD PAR2GRD  BEF_P140 BEF_160 overqualified  \n",
       "0      3.0     9.0       3.0     4.0             0  \n",
       "1      3.0     6.0       3.0     6.0             0  \n",
       "2      NaN     2.0       3.0     3.0             0  \n",
       "3      6.0     3.0       1.0     NaN             0  \n",
       "4      6.0     6.0       3.0     3.0             0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = load_train()\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "### üßπ Preprocessing <a id=\"preprocessing\"></a>\n",
    "\n",
    "`clean()`:\n",
    "- Replaces NGS codes **6, 9, 99** with `NaN` in numeric/code columns  \n",
    "- Normalizes **GENDER2** (e.g. \"Male\" ‚Üí 1, \"Female\" ‚Üí 2)  \n",
    "- Normalizes **DDIS_FL** (\"With disability\" / \"Without disability\")  \n",
    "- Normalizes **VISBMINP** (e.g. \"Yes\" / \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clean-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After clean():\n",
      "  GENDER2 sample values: ['2.0' '9.0' '1.0' '3.0' '0.0']\n",
      "  DDIS_FL sample values: ['2.0' '1.0' '3.0' '0.0']\n",
      "  Null count (should increase where 6/9/99 were replaced): 8706\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = clean(df_raw)\n",
    "print(\"After clean():\")\n",
    "print(\"  GENDER2 sample values:\", df_cleaned[\"GENDER2\"].dropna().astype(str).unique()[:8])\n",
    "print(\"  DDIS_FL sample values:\", df_cleaned[\"DDIS_FL\"].dropna().astype(str).unique()[:8])\n",
    "print(\"  Null count (should increase where 6/9/99 were replaced):\", df_cleaned.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-eng",
   "metadata": {},
   "source": [
    "### üîß Feature Engineering <a id=\"feature-engineering\"></a>\n",
    "\n",
    "`add_features()`:\n",
    "- Converts all survey-code columns to **string** type (CatBoost treats object columns as categorical)  \n",
    "- Fills remaining NaN in those columns with the string `\"missing\"` so CatBoost can use them as a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add-features-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature names (for CatBoost): ['CERTLEVP', 'PGMCIPAP', 'PGM_P034', 'PGM_P036', 'PGM_280A', 'PGM_280B', 'PGM_280C', 'PGM_280F', 'PGM_P401', 'STULOANS', 'DBTOTGRD', 'SCHOLARP', 'PREVLEVP', 'HLOSGRDP', 'GRADAGEP', 'GENDER2', 'CTZSHIPP', 'VISBMINP', 'DDIS_FL', 'PAR1GRD', 'PAR2GRD', 'BEF_P140', 'BEF_160']\n",
      "\n",
      "Sample of engineered columns (string type):\n",
      "CERTLEVP    object\n",
      "PGMCIPAP    object\n",
      "PGM_P034    object\n",
      "PGM_P036    object\n",
      "PGM_280A    object\n",
      "dtype: object\n",
      "\n",
      "Unique values in CERTLEVP (after add_features): ['1' '2' '3' '9' '4' '5' 'missing']\n"
     ]
    }
   ],
   "source": [
    "df_engineered = add_features(df_cleaned)\n",
    "cat_cols = get_categorical_feature_names()\n",
    "print(\"Categorical feature names (for CatBoost):\", cat_cols)\n",
    "print(\"\\nSample of engineered columns (string type):\")\n",
    "print(df_engineered[cat_cols[:5]].dtypes)\n",
    "print(\n",
    "    \"\\nUnique values in CERTLEVP (after add_features):\",\n",
    "    df_engineered[\"CERTLEVP\"].astype(str).unique()[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "before-after",
   "metadata": {},
   "source": [
    "### üìä Before and After Comparison <a id=\"before-and-after-comparison\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compare-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (7709, 25)\n",
      "After clean + add_features: (7709, 25)\n",
      "\n",
      "No rows/columns dropped; only types and values normalized.\n",
      "\n",
      "Pipeline order: load_train() ‚Üí clean() ‚Üí add_features() ‚Üí split_X_y() for model.\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw shape:\", df_raw.shape)\n",
    "print(\"After clean + add_features:\", df_engineered.shape)\n",
    "print(\"\\nNo rows/columns dropped; only types and values normalized.\")\n",
    "print(\"\\nPipeline order: load_train() ‚Üí clean() ‚Üí add_features() ‚Üí split_X_y() for model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Summary\n",
    "\n",
    "Preprocessing and feature engineering produce a single DataFrame that retains `id` and `overqualified` and has all predictor columns as **string-typed categories** suitable for CatBoost. The same sequence is used in `src/train.py` and `src/predict.py`.\n",
    "\n",
    "**Next step:** `03_catboost_training_tuning.ipynb` ‚Äî train and tune the CatBoost model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
